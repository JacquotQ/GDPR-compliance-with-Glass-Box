# -*- coding: utf-8 -*-
"""aaaaaa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_BBesMMhvdA2yGCKYp57XA3p2YHFzope
"""

!pip uninstall -y shap transformers torch scipy

!pip install shap==0.45.0 transformers==4.38.0 torch==2.2.0 scipy==1.10.1

!pip show shap transformers torch scipy

import sys
sys.path.insert(0, '/content/venv/lib/python3.10/site-packages')  # 根据Python版本适配

text_inputs = "Affected_data_volume is unspecific. company_industry is Education. country is Netherlands. data category basic personal data is true. data processing basis performance of public task is true. GDPR clauses are Article 6(1)(e). gdpr_conflict is No conflict. "



import shap
import torch
import numpy as np
from scipy.stats import kendalltau
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# 加载模型和 tokenizer
model_id = "JQ1984/violation_result_GDPR_prediction"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSequenceClassification.from_pretrained(model_id).eval().to("cpu")

# 文本输入（确保是 str）
text_inputs = "Affected_data_volume is unspecific. company_industry is Education. country is Netherlands. data category basic personal data is true. data processing basis performance of public task is true. GDPR clauses are Article 6(1)(e). gdpr_conflict is No conflict."

# 预测函数，确保输出与输入匹配
def predict_proba(texts):
    if not isinstance(texts, list):
        texts = [str(texts)]  # 确保输入为列表格式
    else:
        texts = [str(t) for t in texts]

    encodings = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**encodings).logits
        probs = torch.nn.functional.softmax(outputs, dim=-1)
    return probs.cpu().numpy()

# 使用 SHAP 的文本 masker
masker = shap.maskers.Text(tokenizer)
explainer = shap.Explainer(predict_proba, masker)

# 多次运行获得 SHAP 排名并计算 Kendall tau
shap_rankings = []
for _ in range(10):
    # 确保每次调用 explainer 输入是一个列表
    explanation = explainer(text_inputs)  # 输入是 List[str]

    # 提取 SHAP 值
    shap_values = explanation[0].values
    feature_names = explanation[0].data  # 获取特征名称

    # 打印特征及其 SHAP 值
    print(f"\n第 {_ + 1} 次 SHAP 结果：")
    for feature, shap_value in zip(feature_names, shap_values):
        print(f"{feature}: {shap_value:.4f}")

    # 计算 SHAP 排名（按绝对值排序）
    ranking = np.argsort(-np.abs(shap_values))  # 按绝对值排序
    shap_rankings.append(ranking)

# 计算多次解释的 Kendall tau 一致性
taus = []
for i in range(10):
    for j in range(i + 1, 10):
        tau, _ = kendalltau(shap_rankings[i], shap_rankings[j])
        taus.append(tau)

# 输出平均 Kendall tau 一致性
print(f"\n平均 Kendall tau 一致性: {np.mean(taus):.4f}")
